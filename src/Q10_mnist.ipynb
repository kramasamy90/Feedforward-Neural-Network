{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy on MNIST dataset using top 3 configuration obtained from fashion-MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ann import ann\n",
    "import ann_utils\n",
    "import train_utils\n",
    "import gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 19:58:47.397461: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-20 19:58:47.501152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-20 19:58:47.501171: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-20 19:58:48.114086: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 19:58:48.114174: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-20 19:58:48.114184: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize data\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Meta information about the data.\n",
    "n_train = len(y_train.flatten())\n",
    "n_test = len(y_test.flatten())\n",
    "input_dim = len(X_train[0].flatten())\n",
    "output_dim = 10\n",
    "\n",
    "# Split train data to train and validation sets.\n",
    "ind = [i for i in range(n_train)]\n",
    "np.random.shuffle(ind)\n",
    "m = int(n_train * 0.1)\n",
    "X_valid = X_train[ind[1: m]]\n",
    "y_valid = y_train[ind[1: m]]\n",
    "X_train = X_train[ind[m:]]\n",
    "y_train = y_train[ind[m:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set common hyperparameters\n",
    "ann.batch_size = 64\n",
    "epochs = 10\n",
    "ann.learning_rate = 0.001\n",
    "ann.hidden_size = 128\n",
    "ann.num_layers = 3\n",
    "\n",
    "## Functions\n",
    "ann.weight_init = ann_utils.xavier_init\n",
    "optimizer = gd.adam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set specific hyperparameters.\n",
    "ann.activation = ann_utils.tanh\n",
    "ann.d_activation = ann_utils.d_tanh\n",
    "ann.weight_decay = 0.0\n",
    "\n",
    "# Define an ANN.\n",
    "nn = ann(28 * 28, 10)\n",
    "\n",
    "# Train the ANN.\n",
    "optimizer(nn, X_train, y_train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931155192532089\n",
      "0.7093\n"
     ]
    }
   ],
   "source": [
    "val_acc = train_utils.get_classification_accuracy(nn, X_valid, y_valid)\n",
    "print(val_acc)\n",
    "test_acc = train_utils.get_classification_accuracy(nn, X_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set specific hyperparameters.\n",
    "ann.activation = ann_utils.relu\n",
    "ann.d_activation = ann_utils.d_relu\n",
    "ann.weight_decay = 0.0005\n",
    "\n",
    "# Define an ANN.\n",
    "nn = ann(28 * 28, 10)\n",
    "\n",
    "# Train the ANN.\n",
    "optimizer(nn, X_train, y_train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5320886814469078\n",
      "0.5277\n"
     ]
    }
   ],
   "source": [
    "val_acc = train_utils.get_classification_accuracy(nn, X_valid, y_valid)\n",
    "print(val_acc)\n",
    "test_acc = train_utils.get_classification_accuracy(nn, X_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set specific hyperparameters.\n",
    "ann.activation = ann_utils.tanh\n",
    "ann.d_activation = ann_utils.d_tanh\n",
    "ann.weight_decay = 0.0005\n",
    "\n",
    "# Define an ANN.\n",
    "nn = ann(28 * 28, 10)\n",
    "\n",
    "# Train the ANN.\n",
    "optimizer(nn, X_train, y_train, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7401233538923154\n",
      "0.7471\n"
     ]
    }
   ],
   "source": [
    "val_acc = train_utils.get_classification_accuracy(nn, X_valid, y_valid)\n",
    "print(val_acc)\n",
    "test_acc = train_utils.get_classification_accuracy(nn, X_test, y_test)\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
